# MLOps Project - Vehicle Insurance Data Pipeline

Welcome to the **Vehicle Insurance Data Pipeline** â€“ an end-to-end MLOps project showcasing how real-world machine learning pipelines are designed, built, deployed, and automated using modern tools and platforms. This project is designed to demonstrate data and model handling by implementing industry-standard CI/CD practices, scalable storage (MongoDB + AWS S3), and seamless deployment on AWS EC2 using Docker and GitHub Actions.

---

## ğŸŒ Tech Stack

* **Languages**: Python 3.10
* **Data Storage**: MongoDB Atlas, AWS S3
* **Deployment**: Docker, AWS EC2, GitHub Actions
* **Machine Learning**: scikit-learn, pandas, NumPy
* **MLOps Tools**: GitHub Actions, Docker, PyProject, Conda
* **Others**: HTML/CSS (Flask Web UI), YAML config management

---

## ğŸ“ Project Structure and Setup


```
ğŸ“¦vehicle-classification
 â”£ ğŸ“‚src
 â”ƒ â”£ ğŸ“‚components
 â”ƒ â”£ ğŸ“‚data_access
 â”ƒ â”£ ğŸ“‚aws_storage
 â”ƒ â”£ ğŸ“‚configuration
 â”ƒ â”£ ğŸ“‚entity
 â”ƒ â”£ ğŸ“‚pipeline
 â”ƒ â”— ğŸ“œutils
 â”£ ğŸ“‚notebook
 â”£ ğŸ“‚static
 â”£ ğŸ“‚templates
 â”£ ğŸ“œapp.py
 â”£ ğŸ“œrequirements.txt
 â”£ ğŸ“œDockerfile
 â”£ ğŸ“œ.dockerignore
 â”£ ğŸ“œsetup.py
 â”£ ğŸ“œpyproject.toml
 â”— ğŸ“œREADME.md
```

---

### 1ï¸âƒ£ Project Template Creation

Run `template.py` to automatically generate a clean project structure:

```bash
python template.py
```

This creates all essential modules and files, including:

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ data_ingestion.py, model_trainer.py, ...
â”œâ”€â”€ configuration/
â”‚   â”œâ”€â”€ mongo_db_connection.py, aws_connection.py
â”œâ”€â”€ cloud_storage/
â”œâ”€â”€ data_access/
â”œâ”€â”€ entity/
â”œâ”€â”€ pipeline/
â”œâ”€â”€ utils/
â”œâ”€â”€ exception/, logger/
```

---

## ğŸ§° Environment Setup

### 2ï¸âƒ£ Local Package Management

Configure `setup.py` and `pyproject.toml` to register local packages. Learn more from `crashcourse.txt`.

### 3ï¸âƒ£ Create Virtual Environment

```bash
conda create -n vehicle python=3.10 -y
conda activate vehicle
pip install -r requirements.txt
pip list  # verify installations
```

---

## ğŸƒ MongoDB Atlas Setup

### 4ï¸âƒ£ Steps to Configure MongoDB Atlas

1. Create an account on [MongoDB Atlas](https://www.mongodb.com/cloud/atlas).
2. Create new **M0 cluster** â†’ Define a user with password.
3. Add IP: `0.0.0.0/0` for access from all IPs.
4. Get the **Python connection string**.

### 5ï¸âƒ£ Push Dataset to MongoDB

* Create a `notebook/` folder and add your dataset.
* Use `mongoDB_demo.ipynb` to:

  * Load dataset
  * Push to MongoDB
  * Validate data in Atlas â†’ *Browse Collections*

---

## ğŸ§¾ Logging, Exception Handling, EDA

### 6ï¸âƒ£ Logging and Exception Handling

* Add logging logic in `src/logger/__init__.py`
* Add exception logic in `src/exception/__init__.py`
* Test using `demo.py`

### 7ï¸âƒ£ Perform EDA and Feature Engineering

Use Jupyter notebooks to explore and preprocess data in `notebook/`.

---

## ğŸ“¥ Data Ingestion Pipeline

### 8ï¸âƒ£ Data Ingestion Implementation

* Define MongoDB connector in `configuration/mongo_db_connection.py`
* Access and transform data using `data_access/proj1_data.py`
* Configure ingestion in:

  * `entity/config_entity.py`
  * `entity/artifact_entity.py`
* Logic in `components/data_ingestion.py`
* Update constants in `constants/__init__.py`
* Run ingestion via `pipeline/training_pipeline.py`

### 9ï¸âƒ£ MongoDB URL Setup

```bash
# Bash
export MONGODB_URL="mongodb+srv://<username>:<password>@cluster.mongodb.net"

# PowerShell
$env:MONGODB_URL = "mongodb+srv://<username>:<password>@cluster.mongodb.net"
```

---

## âœ… Data Validation and Transformation

### ğŸ”Ÿ Data Validation

* Schema defined in `config/schema.yaml`
* Implement validation logic in `utils/main_utils.py`
* Add validation logic in `components/data_validation.py`

### 1ï¸âƒ£1ï¸âƒ£ Data Transformation

* Transform logic in `components/data_transformation.py`
* Use `entity/estimator.py` for transformation classes

---

## ğŸ§  Model Training and Evaluation

### 1ï¸âƒ£2ï¸âƒ£ Model Training

* Implement model training in `components/model_trainer.py`
* Update estimator utilities in `entity/estimator.py`

### 1ï¸âƒ£3ï¸âƒ£ Model Evaluation and Pusher (Needs AWS)

Before continuing, configure AWS...

---

## â˜ï¸ AWS Setup for Model Deployment

### 1ï¸âƒ£4ï¸âƒ£ AWS IAM and S3

* Create an IAM User with `AdministratorAccess`
* Generate and download **Access Key & Secret**
* Add credentials as ENV vars:

```bash
# Bash
export AWS_ACCESS_KEY_ID="XXX"
export AWS_SECRET_ACCESS_KEY="XXX"
```

* Add to `constants/__init__.py`:

```python
MODEL_BUCKET_NAME = "my-model-mlopsproj"
MODEL_PUSHER_S3_KEY = "model-registry"
MODEL_EVALUATION_CHANGED_THRESHOLD_SCORE = 0.02
```

### 1ï¸âƒ£5ï¸âƒ£ S3 Bucket Creation

* Go to S3 â†’ Create bucket â†’ `my-model-mlopsproj` (Region: `us-east-1`)
* Uncheck â€œBlock all public accessâ€

### 1ï¸âƒ£6ï¸âƒ£ S3 Logic

* Write push/pull logic in:

  * `cloud_storage/aws_storage.py`
  * `entity/s3_estimator.py`

---

## ğŸ”® Model Evaluation & Prediction

### 1ï¸âƒ£7ï¸âƒ£ Model Evaluation

* Evaluate new model vs old using logic in `components/model_evaluation.py`

### 1ï¸âƒ£8ï¸âƒ£ Model Pusher

* Push the final model to S3 in `components/model_pusher.py`

---

## ğŸ”§ Web UI + Prediction

### 1ï¸âƒ£9ï¸âƒ£ Prediction Pipeline

* Add logic to `pipeline/prediction_pipeline.py`
* Implement web backend in `app.py`

### 2ï¸âƒ£0ï¸âƒ£ Static and Template Setup

* Add `static/` and `templates/` for Flask UI
* Display prediction outputs via HTML interface

---

## ğŸ” CI/CD Automation with Docker, GitHub, EC2

### 2ï¸âƒ£1ï¸âƒ£ Docker + GitHub Actions

* Write `Dockerfile` and `.dockerignore`
* Create `.github/workflows/aws.yaml`

### 2ï¸âƒ£2ï¸âƒ£ GitHub Secrets

Add the following in GitHub â†’ Settings â†’ Secrets:

* `AWS_ACCESS_KEY_ID`
* `AWS_SECRET_ACCESS_KEY`
* `AWS_DEFAULT_REGION`
* `ECR_REPO`

---

## âš™ï¸ AWS EC2 & Docker Deployment

### 2ï¸âƒ£3ï¸âƒ£ EC2 Setup

* Launch EC2 (T2.medium, Ubuntu 24.04)
* Allow port `5080` in Inbound rules
* SSH into instance

### 2ï¸âƒ£4ï¸âƒ£ Install Docker

```bash
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker ubuntu
newgrp docker
```

### 2ï¸âƒ£5ï¸âƒ£ GitHub Self-Hosted Runner

* GitHub â†’ Settings â†’ Actions â†’ Runner â†’ New Self-hosted Runner
* Follow Linux instructions on EC2

```bash
./run.sh  # To keep runner alive
```

---

## ğŸš€ Final Deployment

### 2ï¸âƒ£6ï¸âƒ£ Trigger CI/CD

* Commit changes â†’ GitHub Action triggers â†’ Docker builds & pushes image â†’ EC2 deploys container

### 2ï¸âƒ£7ï¸âƒ£ Access App

* Open browser:

```
http://<EC2_PUBLIC_IP>:5080
```

---

## ğŸ§ª Additional Features

### `/training` Route

Trigger model training from browser.

### GitHub Actions

Full CI/CD integrated. Automates:

* Docker Build
* Push to ECR
* Pull to EC2
* Restart container

---



## ğŸš€ **End-to-End Project Workflow**

```
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚   ğŸ”„ Data Source    â”‚
                      â”‚  MongoDB (Atlas)    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   ğŸ“¥ Data Ingestion   â”‚
                    â”‚ Pull from MongoDB    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  âœ… Data Validation       â”‚
                   â”‚ Check schema & integrity â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚  ğŸ”ƒ Data Transformation     â”‚
                   â”‚  Feature engg + Estimators  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚   ğŸ§  Model Training â”‚
                     â”‚  ML Model & Metrics  â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ğŸ“Š Model Evaluation   â”‚
                    â”‚  Compare & Track Scoresâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ â˜ï¸ Model Deployment     â”‚
                    â”‚ Push to AWS S3 Bucket   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚    ğŸ§ª Prediction API & Web Interface    â”‚
             â”‚ Flask + HTML/CSS in app.py             â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  âš™ï¸ CI/CD Automation with Docker + GitHub Actions +  â”‚
      â”‚         AWS EC2 & ECR (Self-Hosted Runner)           â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§  **High-Level Stages**

| Phase               | Tooling / Libraries Used                                       |
| ------------------- | -------------------------------------------------------------- |
| **Data Storage**    | MongoDB Atlas                                                  |
| **ETL (Ingestion)** | Pandas, Pymongo, Custom Scripts                                |
| **Validation**      | YAML Schema + Custom Validators                                |
| **Transformation**  | Scikit-learn, Pipelines, Feature Engineering                   |
| **Model Training**  | Scikit-learn, Custom Estimator Wrapper (`estimator.py`)        |
| **Evaluation**      | Threshold Metrics, Historical Comparison                       |
| **Deployment**      | AWS S3, Flask App, `model-registry` folder                     |
| **CI/CD**           | Docker, GitHub Actions, AWS EC2, ECR, Self-Hosted Runner       |
| **Web Interface**   | Flask (`app.py`), HTML Templates (`templates/`), Static Assets |

---

## ğŸ› ï¸ **Behind the Scenes â€“ Infra & Automation**

* **Dockerized App**: Ensures cross-platform consistency
* **GitHub Actions**: Automates testing, containerization, and push to AWS
* **AWS EC2**: Host for live Flask API
* **AWS ECR**: Private container registry
* **MongoDB Atlas**: Cloud-hosted database for insurance data
* **Custom Exception & Logging Framework**: Centralized logs for debugging

---
## ğŸ¯ Project Workflow Summary

```mermaid
graph TD;
    A[Data Ingestion] --> B[Data Validation];
    B --> C[Data Transformation];
    C --> D[Model Training];
    D --> E[Model Evaluation];
    E --> F[Model Pusher to S3];
    F --> G[Web App & Prediction];
    G --> H[CI/CD via GitHub Actions + Docker + AWS]
```

---

## Video Demo
ğŸ‘‰ Watch the demo on YouTube: https://youtu.be/o30qj1XNo9s


## ğŸ License

[MIT License](LICENSE)












